{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingClassifier as gbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M02</td>\n",
       "      <td>Produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M0227</td>\n",
       "      <td>Produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M022701</td>\n",
       "      <td>Fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M02270101</td>\n",
       "      <td>Apples</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M02270102</td>\n",
       "      <td>Bananas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M02270103</td>\n",
       "      <td>Berries/Cherries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M02270104</td>\n",
       "      <td>Citrus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M02270105</td>\n",
       "      <td>Grapes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M02270106</td>\n",
       "      <td>Melons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M02270107</td>\n",
       "      <td>Pears</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        code              name\n",
       "0        M02           Produce\n",
       "1      M0227           Produce\n",
       "2    M022701             Fruit\n",
       "3  M02270101            Apples\n",
       "4  M02270102           Bananas\n",
       "5  M02270103  Berries/Cherries\n",
       "6  M02270104            Citrus\n",
       "7  M02270105            Grapes\n",
       "8  M02270106            Melons\n",
       "9  M02270107             Pears"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = pd.read_csv('mch_categories.tsv', sep='\\t')\n",
    "items.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 5, 7, 9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hierarchy_dict = {}\n",
    "for code in items['code']:\n",
    "    if len(code) not in hierarchy_dict:\n",
    "        hierarchy_dict[len(code)] = []\n",
    "    hierarchy_dict[len(code)].append(code)\n",
    "hierarchy_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for length, keys in hierarchy_dict.items():\n",
    "    for key in keys:\n",
    "        items[key] = items['code'].apply(lambda row: int(row[:length] == key))\n",
    "items.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_3, dict_5, dict_7 = {}, {}, {}\n",
    "i,j,k = 1,1,1\n",
    "for key in hierarchy_dict[3]:\n",
    "    dict_3[key] = i\n",
    "    i += 1\n",
    "for key in hierarchy_dict[5]:\n",
    "    dict_5[key] = j\n",
    "    j += 1\n",
    "for key in hierarchy_dict[3]:\n",
    "    dict_7[key] = k\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('products.txt', sep='\\t', header=None)\n",
    "transactions = pd.read_json('transactions.txt', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "791"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items['name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reciept2items(reciept_list, id_exchange):\n",
    "    items = {}\n",
    "    for ix, item_list in enumerate(reciept_list['itemList']):\n",
    "        items[ix] = []\n",
    "        for item_dict in item_list:\n",
    "            item_df = item_dict['item']\n",
    "            item_name = (id_exchange[id_exchange[0] == item_df][2].values[0])\n",
    "            item_id = (id_exchange[id_exchange[0] == item_df][1].values[0])\n",
    "            if item_name != 'Plastic Bags': items[ix].append(item_id)\n",
    "        if ix > 1000: break\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_dict = reciept2items(transactions, products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 8, 916)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(items, item_dict, batch_size=50, maxlen=8):\n",
    "    train, test = [], []\n",
    "    while True:\n",
    "        for reciept in list(item_dict.values()):\n",
    "            result = items[items['code'].isin(reciept)].loc[:,'M02':].to_numpy()[::-1]\n",
    "            if result.shape[0] < maxlen+1: continue\n",
    "            train.append(result[:maxlen])\n",
    "            test.append(result[1:maxlen+1])\n",
    "            if len(train)%batch_size == 0: \n",
    "                yield np.stack(train, axis=0), np.stack(test, axis=0)\n",
    "                train, test = [], []\n",
    "m = load_data(items, item_dict, 50)\n",
    "next(m)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([[ 9.,  9.,  9.,  1.,  9.,  9.,  2.,  9.],\n",
       "         [ 9.,  9.,  9.,  4.,  9.,  9.,  3.,  1.],\n",
       "         [ 9.,  9.,  9.,  6.,  4.,  9.,  9.,  9.],\n",
       "         [ 1.,  9.,  1.,  1.,  9.,  1.,  9.,  9.],\n",
       "         [ 9.,  9.,  9.,  2.,  1.,  9.,  9.,  9.],\n",
       "         [ 1.,  1.,  3.,  1.,  9.,  1.,  1.,  9.],\n",
       "         [ 1.,  9., 15.,  1.,  9.,  9.,  9.,  9.],\n",
       "         [ 9.,  1.,  9.,  9.,  9.,  9.,  1.,  1.]]),\n",
       "  array([[ 9.,  9.,  9.,  4.,  9.,  9.,  3.,  1.],\n",
       "         [ 9.,  9.,  9.,  6.,  4.,  9.,  9.,  9.],\n",
       "         [ 1.,  9.,  1.,  1.,  9.,  1.,  9.,  9.],\n",
       "         [ 9.,  9.,  9.,  2.,  1.,  9.,  9.,  9.],\n",
       "         [ 1.,  1.,  3.,  1.,  9.,  1.,  1.,  9.],\n",
       "         [ 1.,  9., 15.,  1.,  9.,  9.,  9.,  9.],\n",
       "         [ 9.,  1.,  9.,  9.,  9.,  9.,  1.,  1.],\n",
       "         [ 1.,  1.,  1.,  9.,  1.,  9.,  1.,  9.]])),\n",
       " (array([[21., 21., 22.,  1., 22., 21.,  3., 21.],\n",
       "         [24., 21., 21.,  7., 24., 22.,  6.,  2.],\n",
       "         [22., 22., 21., 14.,  7., 21., 24., 24.],\n",
       "         [ 1., 22.,  1.,  1., 22.,  1., 21., 21.],\n",
       "         [21., 21., 22.,  3.,  1., 27., 22., 27.],\n",
       "         [ 1.,  1.,  5.,  1., 23.,  1.,  1., 23.],\n",
       "         [ 1., 21., 38.,  1., 23., 21., 21., 21.],\n",
       "         [21.,  1., 20., 21., 22., 25.,  1.,  1.]]),\n",
       "  array([[24., 21., 21.,  7., 24., 22.,  6.,  2.],\n",
       "         [22., 22., 21., 14.,  7., 21., 24., 24.],\n",
       "         [ 1., 22.,  1.,  1., 22.,  1., 21., 21.],\n",
       "         [21., 21., 22.,  3.,  1., 27., 22., 27.],\n",
       "         [ 1.,  1.,  5.,  1., 23.,  1.,  1., 23.],\n",
       "         [ 1., 21., 38.,  1., 23., 21., 21., 21.],\n",
       "         [21.,  1., 20., 21., 22., 25.,  1.,  1.],\n",
       "         [ 1.,  1.,  1., 22.,  1., 21.,  1., 21.]])),\n",
       " (array([[21., 21., 22.,  1., 22., 21.,  3., 21.],\n",
       "         [24., 21., 21.,  7., 24., 22.,  6.,  2.],\n",
       "         [22., 22., 21., 14.,  7., 21., 24., 24.],\n",
       "         [ 1., 22.,  1.,  1., 22.,  1., 21., 21.],\n",
       "         [21., 21., 22.,  3.,  1., 27., 22., 27.],\n",
       "         [ 1.,  1.,  5.,  1., 23.,  1.,  1., 23.],\n",
       "         [ 1., 21., 38.,  1., 23., 21., 21., 21.],\n",
       "         [21.,  1., 20., 21., 22., 25.,  1.,  1.]]),\n",
       "  array([[24., 21., 21.,  7., 24., 22.,  6.,  2.],\n",
       "         [22., 22., 21., 14.,  7., 21., 24., 24.],\n",
       "         [ 1., 22.,  1.,  1., 22.,  1., 21., 21.],\n",
       "         [21., 21., 22.,  3.,  1., 27., 22., 27.],\n",
       "         [ 1.,  1.,  5.,  1., 23.,  1.,  1., 23.],\n",
       "         [ 1., 21., 38.,  1., 23., 21., 21., 21.],\n",
       "         [21.,  1., 20., 21., 22., 25.,  1.,  1.],\n",
       "         [ 1.,  1.,  1., 22.,  1., 21.,  1., 21.]])))"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data_emb(item_dict, batch_size=8, maxlen=8):\n",
    "    while True:\n",
    "        i = 0\n",
    "        res_1, res_2, res_3 = [], [], []\n",
    "        for lst in list(item_dict.values()):\n",
    "            if len(lst) < maxlen+1:\n",
    "                continue\n",
    "            else:\n",
    "                lst = lst[:maxlen]\n",
    "            r = np.zeros(len(lst))\n",
    "            for ix, itm in enumerate(lst):\n",
    "                for pos, key in enumerate(dict_3.keys()):\n",
    "                    if key == itm[:3]:\n",
    "                        r[ix] = dict_3[key]\n",
    "            res_1.append(r)\n",
    "            r = np.zeros(len(lst))\n",
    "            for ix, itm in enumerate(lst):\n",
    "                for pos, key in enumerate(dict_5.keys()):\n",
    "                    if key == itm[:5]:\n",
    "                        r[ix] = dict_5[key]\n",
    "            res_2.append(r)\n",
    "            for ix, itm in enumerate(lst):\n",
    "                for pos, key in enumerate(dict_7.keys()):\n",
    "                    if key == itm[:7]:\n",
    "                        r[ix] = dict_7[key]\n",
    "            res_3.append(r)\n",
    "            \n",
    "            if i%batch_size == 0 and i:\n",
    "                res_1 = np.stack(res_1, axis=0)\n",
    "                res_2 = np.stack(res_2, axis=0)\n",
    "                res_3 = np.stack(res_3, axis=0)\n",
    "                yield (res_1[:maxlen], res_1[1:]), (res_2[:maxlen], res_2[1:]), (res_3[:maxlen], res_3[1:])\n",
    "                res_1, res_2, res_3 = [], [], []\n",
    "            i += 1\n",
    "m = load_data_emb(item_dict)\n",
    "next(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_52\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_64 (LSTM)               (None, 8, 256)            1201152   \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 8, 64)             81984     \n",
      "_________________________________________________________________\n",
      "lstm_65 (LSTM)               (None, 8, 256)            328704    \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 8, 64)             81984     \n",
      "_________________________________________________________________\n",
      "lstm_66 (LSTM)               (None, 8, 256)            328704    \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 8, 64)             81984     \n",
      "_________________________________________________________________\n",
      "lstm_67 (LSTM)               (None, 8, 256)            328704    \n",
      "_________________________________________________________________\n",
      "time_distributed_49 (TimeDis (None, 8, 916)            235412    \n",
      "=================================================================\n",
      "Total params: 2,668,628\n",
      "Trainable params: 2,668,628\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def LSTM_model(maxlen=8):\n",
    "    # Sequential approach to product prediction\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(maxlen, 916)))\n",
    "    model.add(tf.keras.layers.LSTM(256, activation='relu', dropout=0.2, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.LSTM(256, activation='relu', recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.LSTM(256, activation='relu', recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(tf.keras.layers.Conv1D(filters=64, kernel_size=5, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.LSTM(256, activation='relu', recurrent_dropout=0.2, return_sequences=True))\n",
    "    model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(916, activation='softmax')))\n",
    "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "    return model\n",
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 8s 85ms/step - loss: 7.8599 - accuracy: 0.3694\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 8s 84ms/step - loss: 7.7919 - accuracy: 0.3928\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 7.7006 - accuracy: 0.3706\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 8s 83ms/step - loss: 7.5802 - accuracy: 0.3469\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 7.5004 - accuracy: 0.3609\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 7.3262 - accuracy: 0.3338\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 7.4111 - accuracy: 0.3519\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 8s 82ms/step - loss: 7.3020 - accuracy: 0.3350\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 7.2176 - accuracy: 0.3469\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 7.2770 - accuracy: 0.3447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x208777d2780>"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(load_data(items, item_dict, batch_size=4), steps_per_epoch=100, epochs=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
